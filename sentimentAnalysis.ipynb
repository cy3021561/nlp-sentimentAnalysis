{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\chun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! pip install bs4 \n",
    "# in case you don't have it installed\n",
    "nltk.download('wordnet')\n",
    "# Dataset: https://web.archive.org/web/20201127142707if_/https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "Read the data through pandas packages, using \"usecols\" attribute to filter the data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('./data/amazon_reviews_us_Office_Products_v1_00.tsv', on_bad_lines='skip', usecols=['star_rating', 'review_body'], dtype={'star_rating':'str', 'review_body':'str'})\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Class Label\n",
    "Use the star_rating to get our class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect for planning weekly meals. Removrd the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Gold plated fusers are the best! It will never...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>I have used these highlighters for my bible fo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Heavy pen that writes very well.  I've had it ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Not sure if they work but sent quickly and fit...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  star_rating                                        review_body  class_label\n",
       "0           5                                     Great product.            2\n",
       "1           5  What's to say about this commodity item except...            2\n",
       "2           5    Haven't used yet, but I am sure I will like it.            2\n",
       "3           1  Although this was labeled as &#34;new&#34; the...            1\n",
       "4           4                    Gorgeous colors and easy to use            2\n",
       "5           5  Perfect for planning weekly meals. Removrd the...            2\n",
       "6           5  Gold plated fusers are the best! It will never...            2\n",
       "7           5  I have used these highlighters for my bible fo...            2\n",
       "8           5  Heavy pen that writes very well.  I've had it ...            2\n",
       "9           5  Not sure if they work but sent quickly and fit...            2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['class_label'] = df['star_rating'].astype(int) > 3\n",
    "class_label = []\n",
    "for index, rate in df.iterrows():\n",
    "    if int(rate['star_rating']) > 3:\n",
    "        class_label.append(2)\n",
    "    else:\n",
    "        class_label.append(1)\n",
    "df['class_label'] = class_label\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We form two classes and select 50000 reviews randomly from each class.\n",
    "For each class, use \"groupby\" to selection random 50000 rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.groupby(\"class_label\").sample(n = 50000)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "Define a cleaning function by regex method and import labrary package to clean the review_body text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chun\\AppData\\Local\\Temp\\ipykernel_30928\\404032126.py:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  s = BeautifulSoup(s, 'html.parser').get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning avg :  312.83406 , After cleaning avg :  297.40285\n"
     ]
    }
   ],
   "source": [
    "def cleaning(s):\n",
    "    # Contractions\n",
    "    s = contractions.fix(s)\n",
    "    # Convert to lower case\n",
    "    s = s.lower()\n",
    "    # Remove URLs\n",
    "    s = re.sub(r'(http|www)\\S+', '', s)\n",
    "    # Remove HTML\n",
    "    s = BeautifulSoup(s, 'html.parser').get_text()\n",
    "    # Remove non-alphabetical chracters\n",
    "    s = re.sub(r'[^a-zA-Z\\s]+', '', s)\n",
    "    # Remove extra space\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "df2['cleaned'] = df2['review_body'].apply(lambda context: cleaning(context))\n",
    "df2['before_clean_count'] = df2['review_body'].apply(lambda x : len(x))\n",
    "df2['after_clean_count'] = df2['cleaned'].apply(lambda x : len(x))\n",
    "\n",
    "print('Before cleaning avg : ', df2['before_clean_count'].mean(), ', After cleaning avg : ', df2['after_clean_count'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words \n",
    "Use nltk to remove the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>class_label</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>before_clean_count</th>\n",
       "      <th>after_clean_count</th>\n",
       "      <th>preprocessing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1404872</th>\n",
       "      <td>1</td>\n",
       "      <td>The quality of these is horrible. They fell of...</td>\n",
       "      <td>1</td>\n",
       "      <td>the quality of these is horrible they fell off...</td>\n",
       "      <td>172</td>\n",
       "      <td>168</td>\n",
       "      <td>quality horrible fell boxes within hours going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27285</th>\n",
       "      <td>3</td>\n",
       "      <td>work as described</td>\n",
       "      <td>1</td>\n",
       "      <td>work as described</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>work described</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493466</th>\n",
       "      <td>2</td>\n",
       "      <td>VERY SMALL FOR THE PRICE!!!! I DIDN'T HAVE TIM...</td>\n",
       "      <td>1</td>\n",
       "      <td>very small for the price i did not have time t...</td>\n",
       "      <td>101</td>\n",
       "      <td>97</td>\n",
       "      <td>small price time send back gift cancer patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710841</th>\n",
       "      <td>1</td>\n",
       "      <td>I brought this product and barely used.. i mig...</td>\n",
       "      <td>1</td>\n",
       "      <td>i brought this product and barely used i might...</td>\n",
       "      <td>306</td>\n",
       "      <td>301</td>\n",
       "      <td>brought product barely used might used times e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846563</th>\n",
       "      <td>1</td>\n",
       "      <td>CHEAP - THIN - either plan on doubling the pac...</td>\n",
       "      <td>1</td>\n",
       "      <td>cheap thin either plan on doubling the package...</td>\n",
       "      <td>134</td>\n",
       "      <td>125</td>\n",
       "      <td>cheap thin either plan doubling package ship f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        star_rating                                        review_body  \\\n",
       "1404872           1  The quality of these is horrible. They fell of...   \n",
       "27285             3                                  work as described   \n",
       "1493466           2  VERY SMALL FOR THE PRICE!!!! I DIDN'T HAVE TIM...   \n",
       "1710841           1  I brought this product and barely used.. i mig...   \n",
       "846563            1  CHEAP - THIN - either plan on doubling the pac...   \n",
       "\n",
       "         class_label                                            cleaned  \\\n",
       "1404872            1  the quality of these is horrible they fell off...   \n",
       "27285              1                                  work as described   \n",
       "1493466            1  very small for the price i did not have time t...   \n",
       "1710841            1  i brought this product and barely used i might...   \n",
       "846563             1  cheap thin either plan on doubling the package...   \n",
       "\n",
       "         before_clean_count  after_clean_count  \\\n",
       "1404872                 172                168   \n",
       "27285                    17                 17   \n",
       "1493466                 101                 97   \n",
       "1710841                 306                301   \n",
       "846563                  134                125   \n",
       "\n",
       "                                             preprocessing  \n",
       "1404872  quality horrible fell boxes within hours going...  \n",
       "27285                                       work described  \n",
       "1493466     small price time send back gift cancer patient  \n",
       "1710841  brought product barely used might used times e...  \n",
       "846563   cheap thin either plan doubling package ship f...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(s):\n",
    "    words = s.split(' ')\n",
    "    res = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    return ' '.join(res)\n",
    "\n",
    "df2['preprocessing'] = df2['cleaned'].apply(lambda x: remove_stopwords(x))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization  \n",
    "Use nltk to perform lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing avg :  297.40285 , After preprocessing avg :  184.62694\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>class_label</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>before_clean_count</th>\n",
       "      <th>after_clean_count</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>after_pre_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1404872</th>\n",
       "      <td>1</td>\n",
       "      <td>The quality of these is horrible. They fell of...</td>\n",
       "      <td>1</td>\n",
       "      <td>the quality of these is horrible they fell off...</td>\n",
       "      <td>172</td>\n",
       "      <td>168</td>\n",
       "      <td>quality horrible fell box within hour going wo...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27285</th>\n",
       "      <td>3</td>\n",
       "      <td>work as described</td>\n",
       "      <td>1</td>\n",
       "      <td>work as described</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>work described</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493466</th>\n",
       "      <td>2</td>\n",
       "      <td>VERY SMALL FOR THE PRICE!!!! I DIDN'T HAVE TIM...</td>\n",
       "      <td>1</td>\n",
       "      <td>very small for the price i did not have time t...</td>\n",
       "      <td>101</td>\n",
       "      <td>97</td>\n",
       "      <td>small price time send back gift cancer patient</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710841</th>\n",
       "      <td>1</td>\n",
       "      <td>I brought this product and barely used.. i mig...</td>\n",
       "      <td>1</td>\n",
       "      <td>i brought this product and barely used i might...</td>\n",
       "      <td>306</td>\n",
       "      <td>301</td>\n",
       "      <td>brought product barely used might used time ev...</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846563</th>\n",
       "      <td>1</td>\n",
       "      <td>CHEAP - THIN - either plan on doubling the pac...</td>\n",
       "      <td>1</td>\n",
       "      <td>cheap thin either plan on doubling the package...</td>\n",
       "      <td>134</td>\n",
       "      <td>125</td>\n",
       "      <td>cheap thin either plan doubling package ship f...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        star_rating                                        review_body  \\\n",
       "1404872           1  The quality of these is horrible. They fell of...   \n",
       "27285             3                                  work as described   \n",
       "1493466           2  VERY SMALL FOR THE PRICE!!!! I DIDN'T HAVE TIM...   \n",
       "1710841           1  I brought this product and barely used.. i mig...   \n",
       "846563            1  CHEAP - THIN - either plan on doubling the pac...   \n",
       "\n",
       "         class_label                                            cleaned  \\\n",
       "1404872            1  the quality of these is horrible they fell off...   \n",
       "27285              1                                  work as described   \n",
       "1493466            1  very small for the price i did not have time t...   \n",
       "1710841            1  i brought this product and barely used i might...   \n",
       "846563             1  cheap thin either plan on doubling the package...   \n",
       "\n",
       "         before_clean_count  after_clean_count  \\\n",
       "1404872                 172                168   \n",
       "27285                    17                 17   \n",
       "1493466                 101                 97   \n",
       "1710841                 306                301   \n",
       "846563                  134                125   \n",
       "\n",
       "                                             preprocessing  after_pre_count  \n",
       "1404872  quality horrible fell box within hour going wo...               77  \n",
       "27285                                       work described               14  \n",
       "1493466     small price time send back gift cancer patient               46  \n",
       "1710841  brought product barely used might used time ev...              171  \n",
       "846563   cheap thin either plan doubling package ship f...               78  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(s):\n",
    "    words = s.split(' ')\n",
    "    res = [wordnet_lemmatizer.lemmatize(w) for w in words]\n",
    "    return ' '.join(res)\n",
    "\n",
    "df2['preprocessing'] = df2['preprocessing'].apply(lambda x: lemmatize(x))\n",
    "df2['after_pre_count'] = df2['preprocessing'].apply(lambda x : len(x))\n",
    "\n",
    "print('Before preprocessing avg : ', df2['after_clean_count'].mean(), ', After preprocessing avg : ', df2['after_pre_count'].mean())\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF and BoW Feature Extraction\n",
    "Since the dataset is too large, limited the BoW and TF-IDF features to certain size. In order the avoid the memory issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "df3 = df2['preprocessing']\n",
    "bow_vectorizer = CountVectorizer(max_features=1000)\n",
    "bow_V = bow_vectorizer.fit_transform(df3).toarray()\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_V = tfidf_vectorizer.fit_transform(df3).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_V = df2['class_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset\n",
    "Using sklearn to split the dataset, set the random_state to make sure I have the same dataset for better evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "bow_train, bow_test, bow_label_train, bow_label_test = train_test_split(bow_V, label_V, test_size=0.2, random_state=0)\n",
    "tfidf_train, tfidf_test, tfidf_label_train, tfidf_label_test = train_test_split(tfidf_V, label_V, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Using Both Features\n",
    "Define a evaluation function for calculating the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Perceptron: Precision = 0.7080066524114992, Recall = 0.8946262383668568, F1 = 0.7904509283819628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def calculate_result(tn, fp, fn, tp):\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 / ((1 / precision) + (1 / recall))\n",
    "    return acc, precision, recall, f1\n",
    "    \n",
    "p_bow = Perceptron(random_state=0)\n",
    "p_bow.fit(bow_train, bow_label_train)\n",
    "predictions_test = p_bow.predict(bow_test)\n",
    "tn, fp, fn, tp = confusion_matrix(bow_label_test, predictions_test).ravel()\n",
    "acc, precision, recall, f1 = calculate_result(tn, fp, fn, tp)\n",
    "print(\"BoW Perceptron: Precision = \" + str(precision) + \", Recall = \" + str(recall) + \", F1 = \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Perceptron: Precision = 0.8708240534521158, Recall = 0.6260382267587311, F1 = 0.7284159049892297\n"
     ]
    }
   ],
   "source": [
    "p_tfidf = Perceptron(random_state=0)\n",
    "p_tfidf.fit(tfidf_train, tfidf_label_train)\n",
    "predictions_test = p_tfidf.predict(tfidf_test)\n",
    "tn, fp, fn, tp = confusion_matrix(tfidf_label_test, predictions_test).ravel()\n",
    "acc, precision, recall, f1 = calculate_result(tn, fp, fn, tp)\n",
    "print(\"TF-IDF Perceptron: Precision = \" + str(precision) + \", Recall = \" + str(recall) + \", F1 = \" + str(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Using Both Features\n",
    "Set the iteration times to avoid wasting too long for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW SVM: Precision = 0.8138993893573714, Recall = 0.8402882017412189, F1 = 0.8268833087149189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chun\\anaconda3\\envs\\CS544\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "bow_svm = LinearSVC(max_iter=1000)\n",
    "bow_svm.fit(bow_train, bow_label_train)\n",
    "predictions_test = bow_svm.predict(bow_test)\n",
    "tn, fp, fn, tp = confusion_matrix(bow_label_test, predictions_test).ravel()\n",
    "acc, precision, recall, f1 = calculate_result(tn, fp, fn, tp)\n",
    "print(\"BoW SVM: Precision = \" + str(precision) + \", Recall = \" + str(recall) + \", F1 = \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF SVM: Precision = 0.8323863636363636, Recall = 0.8209746822775943, F1 = 0.8266411406116179\n"
     ]
    }
   ],
   "source": [
    "tfidf_svm = LinearSVC(max_iter=1000)\n",
    "tfidf_svm.fit(tfidf_train, tfidf_label_train)\n",
    "predictions_test = tfidf_svm.predict(tfidf_test)\n",
    "tn, fp, fn, tp = confusion_matrix(tfidf_label_test, predictions_test).ravel()\n",
    "acc, precision, recall, f1 = calculate_result(tn, fp, fn, tp)\n",
    "print(\"TF-IDF SVM: Precision = \" + str(precision) + \", Recall = \" + str(recall) + \", F1 = \" + str(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Using Both Features\n",
    "Set the iteration times to avoid wasting too long for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Logistic Regression: Precision = 0.816364345621221, Recall = 0.8376863804663264, F1 = 0.8268879340149157\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "bow_lr = LogisticRegression(max_iter=1000)\n",
    "bow_lr.fit(bow_train, bow_label_train)\n",
    "predictions_test = bow_lr.predict(bow_test)\n",
    "tn, fp, fn, tp = confusion_matrix(bow_label_test, predictions_test).ravel()\n",
    "acc, precision, recall, f1 = calculate_result(tn, fp, fn, tp)\n",
    "print(\"BoW Logistic Regression: Precision = \" + str(precision) + \", Recall = \" + str(recall) + \", F1 = \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic Regression: Precision = 0.834335814048323, Recall = 0.8189732812969078, F1 = 0.8265831734168266\n"
     ]
    }
   ],
   "source": [
    "tfidf_lr = LogisticRegression(max_iter=1000)\n",
    "tfidf_lr.fit(tfidf_train, tfidf_label_train)\n",
    "predictions_test = tfidf_lr.predict(tfidf_test)\n",
    "tn, fp, fn, tp = confusion_matrix(tfidf_label_test, predictions_test).ravel()\n",
    "acc, precision, recall, f1 = calculate_result(tn, fp, fn, tp)\n",
    "print(\"TF-IDF Logistic Regression: Precision = \" + str(precision) + \", Recall = \" + str(recall) + \", F1 = \" + str(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Using Both Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Naive Bayes: Precision = 0.6378685980341439, Recall = 0.8637045932152507, F1 = 0.7338037748682197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "bow_nb = GaussianNB()\n",
    "bow_nb.fit(bow_train, bow_label_train)\n",
    "predictions_test = bow_nb.predict(bow_test)\n",
    "tn, fp, fn, tp = confusion_matrix(bow_label_test, predictions_test).ravel()\n",
    "acc, precision, recall, f1 = calculate_result(tn, fp, fn, tp)\n",
    "print(\"BoW Naive Bayes: Precision = \" + str(precision) + \", Recall = \" + str(recall) + \", F1 = \" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Naive Bayes: Precision = 0.7638942868247183, Recall = 0.7867507255078555, F1 = 0.7751540547202367\n"
     ]
    }
   ],
   "source": [
    "tfidf_nb = GaussianNB()\n",
    "tfidf_nb.fit(tfidf_train, tfidf_label_train)\n",
    "predictions_test = tfidf_nb.predict(tfidf_test)\n",
    "tn, fp, fn, tp = confusion_matrix(tfidf_label_test, predictions_test).ravel()\n",
    "acc, precision, recall, f1 = calculate_result(tn, fp, fn, tp)\n",
    "print(\"TF-IDF Naive Bayes: Precision = \" + str(precision) + \", Recall = \" + str(recall) + \", F1 = \" + str(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
